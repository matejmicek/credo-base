import { logger, task, metadata, batch } from "@trigger.dev/sdk/v3";
import { prisma } from "../lib/prisma";
import { uploadToOpenAITask } from "./uploadToOpenAI";
import { analyzeDealTask } from "./analyzeDeal";
import { analyzeCompetitorsTask } from "./analyzeCompetitors";
import { ALL_COMPETITOR_TYPES } from "./utils/sanitize";
import { evaluateCompetitorTask } from "./evaluateCompetitor";

export type UploadOrchestratorPayload = {
  dealId: string; // Now we work with an existing deal
  userId: string;
  s3Files: Array<{
    s3Url: string;
    originalFilename: string;
    mimetype: string;
    size: number;
  }>;
  freeText?: string;
};

export const uploadOrchestratorTask = task({
  id: "upload-orchestrator",
  maxDuration: 1800, // 30 minutes
  run: async (payload: UploadOrchestratorPayload) => {
    console.log("ğŸš€ Starting upload orchestration process");
    console.log("ğŸ“‹ Payload received:", {
      dealId: payload.dealId,
      userId: payload.userId,
      fileCount: payload.s3Files?.length || 0,
      hasFreeText: !!payload.freeText
    });
    
    console.log("ğŸ” Validating payload requirements...");
    if (!payload.dealId) {
      console.error("âŒ Missing dealId in payload");
      throw new Error("dealId is required");
    }
    if (!payload.userId) {
      console.error("âŒ Missing userId in payload");
      throw new Error("userId is required");
    }

    if (!payload.s3Files || payload.s3Files.length === 0) {
      if (!payload.freeText) {
        console.error("âŒ Neither s3Files nor freeText provided");
        throw new Error("Either s3Files or freeText must be provided");
      }
    }

    console.log("âœ… Payload validation successful");
    console.log("ğŸ“Š Processing details:");
    console.log("  ğŸ¯ Deal ID:", payload.dealId);
    console.log("  ğŸ‘¤ User ID:", payload.userId);
    console.log("  ğŸ“ File count:", payload.s3Files?.length || 0);
    console.log("  ğŸ“ Has free text:", !!payload.freeText);

    logger.log("Starting upload orchestration", {
      dealId: payload.dealId,
      userId: payload.userId,
      fileCount: payload.s3Files?.length || 0,
      hasFreeText: !!payload.freeText,
    });

    metadata.set("status", { label: "Initializing upload process", progress: 5 });

    // Step 1: Upload files to OpenAI (S3 upload already done in API)
    console.log("ğŸ“¤ Step 1: Preparing OpenAI file uploads...");
    let openaiResults: any[] = [];

    if (payload.s3Files && payload.s3Files.length > 0) {
      console.log("ğŸ”„ Files detected, starting OpenAI upload process");
      console.log("ğŸ“Š Files to upload:", payload.s3Files.map(f => f.originalFilename));
      metadata.set("status", { label: "Uploading files to OpenAI", progress: 15 });

      console.log("ğŸš€ Triggering OpenAI upload task...");
      const uploadResults = await batch.triggerByTaskAndWait([
        {
          task: uploadToOpenAITask,
          payload: { s3Files: payload.s3Files },
        },
      ]);

      console.log("ğŸ“¥ OpenAI upload task completed, checking results...");
      const [openaiRun] = uploadResults.runs;

      if (!openaiRun.ok) {
        console.error("âŒ OpenAI upload task failed");
        logger.error("OpenAI upload failed", { error: (openaiRun as any).error });
        throw new Error(`OpenAI upload failed: ${(openaiRun as any).error}`);
      }

      openaiResults = openaiRun.output;
      console.log("âœ… OpenAI upload successful!");
      console.log("ğŸ“‹ Upload results summary:");
      console.log("  ğŸ“ Total results:", openaiResults.length);
      console.log("  âœ… Successful uploads:", openaiResults.filter(r => r.openaiFileId).length);
      console.log("  âŒ Failed uploads:", openaiResults.filter(r => !r.openaiFileId).length);

      logger.log("OpenAI upload completed", {
        openaiCount: openaiResults.length,
      });
    } else {
      console.log("â„¹ï¸ No files to upload to OpenAI, skipping upload step");
    }

    metadata.set("status", { label: "Processing uploaded files", progress: 40 });

    // Step 2: Update file records with OpenAI file IDs FIRST
    console.log("ğŸ”„ Step 2: Processing OpenAI upload results...");
    const openaiFileIds = openaiResults.map(result => result.openaiFileId).filter(Boolean);
    
    console.log("ğŸ“Š OpenAI file ID extraction complete:");
    console.log("  ğŸ“ Total upload results:", openaiResults.length);
    console.log("  âœ… Valid file IDs:", openaiFileIds.length);
    console.log("  ğŸ”— File IDs:", openaiFileIds);
    
    logger.log("Prepared OpenAI file IDs for analysis", {
      totalResults: openaiResults.length,
      validFileIds: openaiFileIds.length,
      fileIds: openaiFileIds
    });

    if (payload.s3Files && payload.s3Files.length > 0 && openaiResults.length > 0) {
      console.log("ğŸ’¾ Updating database records with OpenAI file IDs...");
      let updatedCount = 0;
      
      for (let i = 0; i < payload.s3Files.length; i++) {
        const file = payload.s3Files[i];
        const openaiResult = openaiResults[i];
        
        if (openaiResult?.openaiFileId) {
          console.log(`ğŸ”— Updating file record: ${file.originalFilename} -> ${openaiResult.openaiFileId}`);
          await prisma.dealFile.updateMany({
            where: {
              dealId: payload.dealId,
              originalName: file.originalFilename,
              url: file.s3Url,
            },
            data: {
              openaiFileId: openaiResult.openaiFileId,
            },
          });
          updatedCount++;
        } else {
          console.log(`âš ï¸ No OpenAI file ID for: ${file.originalFilename}`);
        }
      }

      console.log("âœ… Database update complete!");
      console.log(`ğŸ“Š Updated ${updatedCount} file records with OpenAI IDs`);
      
      logger.log("File records updated with OpenAI file IDs", { 
        count: openaiResults.filter(r => r.openaiFileId).length 
      });
    } else {
      console.log("â„¹ï¸ No file records to update, skipping database update step");
    }

    metadata.set("status", { label: "Starting document analysis", progress: 50 });

    // Step 3: Analyze deal documents and competitors in parallel
    console.log("ğŸ” Step 3: Starting comprehensive document analysis...");
    console.log("ğŸ“Š Analysis tasks to run:");
    console.log("  ğŸ“ Deal analysis task");
    console.log("  ğŸ¢ Competitor analysis tasks:", ALL_COMPETITOR_TYPES.length);
    console.log("  ğŸ¯ Competitor types:", ALL_COMPETITOR_TYPES);
    
    console.log("ğŸš€ Triggering parallel analysis tasks...");
    const analysisResults = await batch.triggerByTaskAndWait([
      {
        task: analyzeDealTask,
        payload: {
          openaiFileIds,
          freeText: payload.freeText,
        },
      },
      ...ALL_COMPETITOR_TYPES.map((competitorType) => ({
        task: analyzeCompetitorsTask,
        payload: {
          dealId: payload.dealId,
          competitorType,
        },
      })),
    ]);

    console.log("ğŸ“¥ Analysis tasks completed, processing results...");
    const [dealAnalysisRun, ...competitorAnalysisRuns] = analysisResults.runs;

    console.log("ğŸ” Checking deal analysis results...");
    if (!dealAnalysisRun.ok) {
      console.error("âŒ Deal analysis task failed");
      logger.error("Deal analysis failed", { error: (dealAnalysisRun as any).error });
      throw new Error(`Deal analysis failed: ${(dealAnalysisRun as any).error}`);
    }
    console.log("âœ… Deal analysis completed successfully");

    console.log("ğŸ¢ Processing competitor analysis results...");
    const competitorIds: string[] = [];
    let successfulCompetitorRuns = 0;
    let failedCompetitorRuns = 0;
    
    for (const run of competitorAnalysisRuns) {
      if (!run.ok) {
        console.error("âŒ Competitor analysis run failed:", (run as any).error);
        logger.error("Competitor analysis failed", { error: (run as any).error });
        failedCompetitorRuns++;
        continue;
      }
      const out = run.output as any;
      if (out?.competitorIds && Array.isArray(out.competitorIds)) {
        console.log(`âœ… Found ${out.competitorIds.length} competitors from this analysis`);
        competitorIds.push(...out.competitorIds);
        successfulCompetitorRuns++;
      } else {
        console.log("â„¹ï¸ No competitors found in this analysis run");
        successfulCompetitorRuns++;
      }
    }
    
    console.log("ğŸ“Š Competitor analysis summary:");
    console.log("  âœ… Successful runs:", successfulCompetitorRuns);
    console.log("  âŒ Failed runs:", failedCompetitorRuns);
    console.log("  ğŸ¢ Total competitors found:", competitorIds.length);

    const dealAnalysis = dealAnalysisRun.output;
    const competitorAnalysis = null; // Results are saved directly per-competitor; nothing to aggregate here

    // Step 4: Evaluate all created competitors in parallel
    console.log("âš–ï¸ Step 4: Starting competitor evaluations...");
    if (competitorIds.length > 0) {
      console.log(`ğŸš€ Triggering ${competitorIds.length} competitor evaluation tasks`);
      console.log("ğŸ¢ Competitor IDs to evaluate:", competitorIds);
      
      logger.log("Triggering competitor evaluations", { count: competitorIds.length });
      await batch.triggerByTaskAndWait(
        competitorIds.map((competitorId) => ({
          task: evaluateCompetitorTask,
          payload: { competitorId },
        }))
      );
      console.log("âœ… All competitor evaluations completed");
    } else {
      console.log("â„¹ï¸ No competitors found to evaluate, skipping evaluation step");
    }

    metadata.set("status", { label: "Updating deal with extracted information", progress: 80 });

    // Step 5: Update existing deal record with extracted data
    console.log("ğŸ’¾ Step 5: Updating deal record with extracted information...");
    console.log("ğŸ“Š Deal analysis results to save:");
    console.log("  ğŸ¢ Company name:", dealAnalysis.deal_name);
    console.log("  ğŸ“ Description length:", dealAnalysis.deal_description?.length || 0, "characters");
    console.log("  ğŸ‘¥ Founding team members:", dealAnalysis.deal_founding_team?.length || 0);
    
    const deal = await prisma.deal.update({
      where: { id: payload.dealId },
      data: {
        companyName: dealAnalysis.deal_name,
        description: dealAnalysis.deal_description,
        foundingTeam: dealAnalysis.deal_founding_team,
      },
    });

    console.log("âœ… Deal record updated successfully!");
    console.log("ğŸ¯ Updated deal ID:", deal.id);
    
    logger.log("Deal updated with extracted information", { dealId: deal.id });

    metadata.set("status", { label: "Upload orchestration completed", progress: 100 });

    // Return the updated deal with files
    console.log("ğŸ“‹ Fetching final deal data with files...");
    const dealWithFiles = await prisma.deal.findUnique({
      where: { id: payload.dealId },
      include: { files: true },
    });

    console.log("ğŸ‰ Upload orchestration completed successfully!");
    console.log("ğŸ“Š Final summary:");
    console.log("  ğŸ¯ Deal ID:", dealWithFiles?.id);
    console.log("  ğŸ“ Files attached:", dealWithFiles?.files?.length || 0);
    console.log("  ğŸ¢ Competitors found:", competitorIds.length);

    return {
      success: true,
      deal: dealWithFiles,
    };
  },
});
